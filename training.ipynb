{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from src.transforms import AddGaussianNoise\n",
    "from src.transforms import AddSaltPepperNoise\n",
    "from src.transforms import AddBlockNoise\n",
    "from src.transforms import ClampTensor\n",
    "\n",
    "from src.autoencoder import Autoencoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set random seed for numpy\n",
    "_ = np.random.seed(RANDOM_SEED)\n",
    "# Set random seed for pytorch\n",
    "_ = torch.random.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get devices\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "MNIST_DIR_PATH = './data'  # MNIST dataset directory\n",
    "MNIST_DOWNLOAD = True  # Enable MNIST download/overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2dbf5227a1c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Check training dataset shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test dataset has %d images'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Show some sample of training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Load/download MNIST dataset\n",
    "\n",
    "# Define a simple transformer pipeline for test dataset\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ClampTensor()\n",
    "])\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = MNIST(MNIST_DIR_PATH, train=False, download=MNIST_DOWNLOAD, transform=test_transform)\n",
    "\n",
    "# Check training dataset shape\n",
    "print('Test dataset has %d images' % len(test_dataset))\n",
    "\n",
    "# Show some sample of training dataset\n",
    "fig, axs = plt.subplots(1, 7, figsize=(14, 2))\n",
    "# Loop through each subplot\n",
    "for ax in axs.flatten():\n",
    "    # Get an image and the corresponding label\n",
    "    img, label = test_dataset[np.random.choice(len(test_dataset))]\n",
    "    ax.imshow(img.squeeze().numpy(), cmap='gist_gray')  # Show grayscale image\n",
    "    ax.set_title('Label: %d' % label)  # Show label in title\n",
    "    ax.set_xticks([])  # Remove x-axis ticks\n",
    "    ax.set_yticks([])  # Remove y-axis ticks\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset: it is a concatenation of either original and noised datasets\n",
    "train_dataset_list = [\n",
    "    # Original MNIST training dataset\n",
    "    MNIST(MNIST_DIR_PATH, train=True, download=MNIST_DOWNLOAD, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        ClampTensor()\n",
    "    ])),\n",
    "    # Gaussian noised MNIST training dataset\n",
    "    MNIST(MNIST_DIR_PATH, train=True, download=MNIST_DOWNLOAD, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        AddGaussianNoise(mean=0.0, std=0.5),\n",
    "        ClampTensor()\n",
    "    ])),\n",
    "    # Salt and pepper noised MNIST training dataset\n",
    "    MNIST(MNIST_DIR_PATH, train=True, download=MNIST_DOWNLOAD, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        AddSaltPepperNoise(percentage=0.6),\n",
    "        ClampTensor()\n",
    "    ])),\n",
    "    # Block noised MNIST training dataset\n",
    "    MNIST(MNIST_DIR_PATH, train=True, download=MNIST_DOWNLOAD, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        AddBlockNoise(percentage=0.45),\n",
    "        ClampTensor()\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# Check training dataset shape\n",
    "print('Default training dataset has {:d} images'.format(len(train_dataset_list[0])))\n",
    "print('Therefore, in training dataset with noise there will be {:d} x {:d} = {:d} images'.format(\n",
    "    len(train_dataset_list[0]), len(train_dataset_list), \n",
    "    len(train_dataset_list[0]) * len(train_dataset_list)\n",
    "))\n",
    "\n",
    "# Show some sample of training datasets\n",
    "fig, axs = plt.subplots(4, 7, figsize=(14, 8))\n",
    "# Loop through each row\n",
    "for i in range(axs.shape[0]):\n",
    "    # Define current dataset\n",
    "    curr_dataset = train_dataset_list[i]\n",
    "    # Get current dataset length\n",
    "    n = len(curr_dataset)\n",
    "    # Loop through each column\n",
    "    for j in range(axs.shape[1]):\n",
    "        # Get an image and the corresponding label from current dataset\n",
    "        img, label = curr_dataset[np.random.choice(n)]\n",
    "        # Show grayscale image\n",
    "        axs[i, j].imshow(img.squeeze().numpy(), cmap='gist_gray')\n",
    "        axs[i, j].set_title('Label: %d' % label)  # Show label in title\n",
    "        axs[i, j].set_xticks([])  # Remove x-axis ticks\n",
    "        axs[i, j].set_yticks([])  # Remove y-axis ticks\n",
    "# Show plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single training dataset instance\n",
    "train_dataset = ConcatDataset(train_dataset_list)\n",
    "\n",
    "# Check training dataset shape\n",
    "print('Training dataset with noise has %d images' % len(train_dataset))\n",
    "\n",
    "# Show some sample of training dataset\n",
    "fig, axs = plt.subplots(1, 7, figsize=(14, 2))\n",
    "# Loop through each subplot\n",
    "for ax in axs.flatten():\n",
    "    # Get an image and the corresponding label\n",
    "    img, label = train_dataset[np.random.choice(len(train_dataset))]\n",
    "    ax.imshow(img.squeeze().numpy(), cmap='gist_gray')  # Show grayscale image\n",
    "    ax.set_title('Label: %d' % label)  # Show label in title\n",
    "    ax.set_xticks([])  # Remove x-axis ticks\n",
    "    ax.set_yticks([])  # Remove y-axis ticks\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new simple autoencoder by first initializing its components\n",
    "\n",
    "# Convolutional encoder\n",
    "encoder_cnn = nn.Sequential(\n",
    "    nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "    nn.ReLU(True),\n",
    "    nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "    nn.ReLU(True),\n",
    "    nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "    nn.ReLU(True)\n",
    ")\n",
    "\n",
    "# Test convolutional encoder: get convolutional to linear transformations\n",
    "out = encoder_cnn(torch.rand((1, 1, 28, 28), dtype=torch.float))\n",
    "# Print out shape\n",
    "print('Last convolutional layer has shape %s' % str(tuple(out.size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear encoder\n",
    "encoder_lin = nn.Sequential(\n",
    "    # Set first linear layer according to last cnn layer (3 * 3 * 32)\n",
    "    nn.Linear(3 * 3 * 32, 64),  \n",
    "    nn.ReLU(True),\n",
    "    # Define last encoder linear layer size (16)\n",
    "    nn.Linear(64, 16)\n",
    ")\n",
    "\n",
    "# Linear decoder\n",
    "decoder_lin = nn.Sequential(\n",
    "    # Set first decoder linear layer according to last encoder linear layer \n",
    "    nn.Linear(16, 64),\n",
    "    nn.ReLU(True),\n",
    "    # Set decoder last linear layer specularly to first encoder linear layer \n",
    "    nn.Linear(64, 3 * 3 * 32),\n",
    "    nn.ReLU(True)\n",
    ")\n",
    "\n",
    "# Convolutional decoder\n",
    "decoder_cnn = nn.Sequential(\n",
    "    # Set decoder first cnn layer specularly to last encoder cnn layer\n",
    "    nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    ")\n",
    "\n",
    "# Generate the autoencoder\n",
    "net = Autoencoder(encoder_cnn, encoder_lin, decoder_lin, decoder_cnn, lin_to_cnn = (32, 3, 3))\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataloaders\n",
    "\n",
    "# Define training dataloader settings\n",
    "BATCH_SIZE=512\n",
    "SHUFFLE = True\n",
    "\n",
    "# Initialize train dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "# Initialize test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out, loss = net.test_batch(\n",
    "#     batch=next(iter(test_dataloader)), \n",
    "#     loss_fn=nn.MSELoss()\n",
    "# )\n",
    "# \n",
    "# loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively train and test the autoencoder\n",
    "\n",
    "# Define number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "LINEAR_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=LINEAR_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Execute training\n",
    "train_loss, test_loss = net.train_epochs(\n",
    "    num_epochs=NUM_EPOCHS, train_dataloader=train_dataloader, test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer, loss_fn=loss_fn, device=device, verbose=True\n",
    ")\n",
    "\n",
    "# Plot losses\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 7))\n",
    "_ = ax.set_title('Train vs test loss')\n",
    "_ = ax.plot(x=range(0, len(train_loss)), y=train_loss)\n",
    "_ = ax.plot(x=range(0, len(train_loss), len(train_loss) / NUM_EPOCHS), y=test_loss)\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
